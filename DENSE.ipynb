{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import os\n",
    "from keras.engine import training_utils  \n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import preprocessing\n",
    "\n",
    "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 12  # how far into the future are we trying to predict?\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "EPOCHS = 100  # how many passes through our data\n",
    "# how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "BATCH_SIZE = 128  # 64\n",
    "\n",
    "NNNAME = \"DENSE\"\n",
    "\n",
    "NAME = f\"{NNNAME}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "\n",
    "SAVE = True\n",
    "\n",
    "# Create models folder\n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify(df):\n",
    "    change = 0.0015\n",
    "    for i, row in df.iterrows():\n",
    "        target = 1\n",
    "        if df.at[i, \"future_best_bid\"] > df.at[i, \"best_ask\"] * (1 + change): # good to buy now\n",
    "            target = 2\n",
    "        elif df.at[i, \"future_best_ask\"] * (1 + change) < df.at[i, \"best_bid\"]: # good to sell now  \n",
    "            target = 0\n",
    "        df.at[i,\"target\"] = target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df, shorten=False):\n",
    "    df = df.loc[:,~df.columns.str.startswith('future_')]\n",
    "    \n",
    "    sprd = 2 * (df[\"best_ask\"] - df[\"best_bid\"]) / (df[\"best_ask\"] + df[\"best_bid\"])\n",
    "    df.insert(2, \"spread\", sprd)\n",
    "    \n",
    "    ob_maxsum = df.filter(regex=\"(a|b)\\d\").sum(axis=1).max()\n",
    "    ob_maxamt = df.filter(regex=\"last_buy_amt|last_sell_amt\").sum(axis=1).max()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in [\"target\", \"spread\"]:  # normalize all except for target, spread already done\n",
    "            continue\n",
    "        \n",
    "        if col in [\"best_ask\", \"best_bid\", \"last_buy_price\", \"last_sell_price\"]:\n",
    "            df[col] = df[col].pct_change()\n",
    "        elif col in [\"last_buy_amt\", \"last_sell_amt\"]:\n",
    "            df[col] = df[col] / ob_maxamt # preprocessing.scale(df[col].values)\n",
    "        else:\n",
    "            df[col] = df[col]/ob_maxsum\n",
    "            \n",
    "        df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "   \n",
    "    \n",
    "    df.dropna(inplace=True)  # cleanup again... jic.\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "    \n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            # append those bad boys!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "    holds = []\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 1:\n",
    "            holds.append([seq, target])\n",
    "        elif target == 2:\n",
    "            buys.append([seq, target])\n",
    "        elif target == 0:\n",
    "            sells.append([seq, target])\n",
    "\n",
    "    if shorten:\n",
    "        # make sure both lists are only up to the shortest length.\n",
    "        minlen = min(len(buys), len(sells), len(holds))\n",
    "        buys = buys[:minlen]\n",
    "        sells = sells[:minlen]\n",
    "        holds = holds[:minlen]\n",
    "\n",
    "\n",
    "    sequential_data = buys+sells+holds  # add them together\n",
    "    # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        x.append(seq)  # x is the sequences\n",
    "        y.append(target)  # y is the targets/labels\n",
    "\n",
    "    return np.array(x), y \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/reaal/Desktop/btc/env/streams/collector/obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-08-21.49.47.83_17196840.csv' does not exist: b'/Users/reaal/Desktop/btc/env/streams/collector/obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-08-21.49.47.83_17196840.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f5f91346325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_init_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_init_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_ob_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ffill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4f5f91346325>\u001b[0m in \u001b[0;36mread_ob_csv\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_ob_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/reaal/Desktop/btc/env/streams/collector/obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-08-21.49.47.83_17196840.csv' does not exist: b'/Users/reaal/Desktop/btc/env/streams/collector/obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-08-21.49.47.83_17196840.csv'"
     ]
    }
   ],
   "source": [
    "path = \"/Users/Ranykhalil/Downloads/Archive_2/\"\n",
    "# data_file = \"obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-04-16.49.47.83_17196840.csv\"\n",
    "# data_file = \"obbinsandtrades_ETH-USD_2020-03-26-23.49.57.83_2020-04-03-15.49.47.83_17196840.csv\"\n",
    "data_file = \"obbinsandtrades_BTC-USD_2020-03-26-23.49.57.83_2020-04-08-21.49.47.83_17196840.csv\"\n",
    "\n",
    "def read_ob_csv(file):\n",
    "    df = pd.read_csv(path + file)\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    df_len = len(df.index.unique())\n",
    "    df_interval = df.index.unique()[1] - df.index.unique()[0]\n",
    "    df_init_t = df.index.unique()[0]\n",
    "    df_bins = len(df.loc[df.index == df_init_t].columns) - 6\n",
    "    return df_len, df_interval, df_init_t, df_bins, df\n",
    "\n",
    "df_len, df_interval, df_init_t, df_bins, df = read_ob_csv(data_file)\n",
    "\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SELL  HOLD  BUY ]\n",
      "[9056, 88077, 9415]\n"
     ]
    }
   ],
   "source": [
    "if \"future_best_ask\" not in df.columns:\n",
    "    for col in df.columns:\n",
    "        df['future_'+col] = df[col].shift(-FUTURE_PERIOD_PREDICT)\n",
    "    \n",
    "classify(df)\n",
    "df.dropna(inplace=True)\n",
    "print(\"[ SELL  HOLD  BUY ]\")\n",
    "print(df.groupby(\"target\").count()[\"best_ask\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape tr x (85176, 60, 207)\n",
      "shape tr y (85176,)\n",
      "shape val x (21246, 60, 207)\n",
      "shape val y (21246,)\n"
     ]
    }
   ],
   "source": [
    "times = sorted(df.index.values)\n",
    "validation_times = sorted(df.index.values)[-int(VALIDATION_SPLIT*len(times))]\n",
    "\n",
    "validation_df = df[(df.index >= validation_times)]\n",
    "df = df[(df.index < validation_times)]\n",
    "\n",
    "\n",
    "train_x, train_y = preprocess(df, False)\n",
    "validation_x, validation_y = preprocess(validation_df, False)\n",
    "\n",
    "print(\"shape tr x\", np.shape(train_x))\n",
    "print(\"shape tr y\", np.shape(train_y))\n",
    "print(\"shape val x\", np.shape(validation_x))\n",
    "print(\"shape val y\", np.shape(validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "### TRAIN      \t total: 85176 \t holds: 70239 \t buys: 7634 \t sells: 7303\n",
      "### VALIDATION \t total: 21246 \t holds: 17748 \t buys: 1774 \t sells: 1724\n",
      "###\n",
      "(85176, 60, 207)\n",
      "(60, 207)\n",
      "Train on 85176 samples, validate on 21246 samples\n",
      "Epoch 1/100\n",
      "85176/85176 [==============================] - 44s 521us/sample - loss: 1.1387 - sparse_categorical_accuracy: 0.4169 - val_loss: 0.9477 - val_sparse_categorical_accuracy: 0.6391\n",
      "Epoch 2/100\n",
      "85176/85176 [==============================] - 39s 461us/sample - loss: 0.9912 - sparse_categorical_accuracy: 0.4789 - val_loss: 1.1051 - val_sparse_categorical_accuracy: 0.3698\n",
      "Epoch 3/100\n",
      "85176/85176 [==============================] - 56s 656us/sample - loss: 0.8754 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.9240 - val_sparse_categorical_accuracy: 0.5541\n",
      "Epoch 4/100\n",
      "85176/85176 [==============================] - 51s 593us/sample - loss: 0.7488 - sparse_categorical_accuracy: 0.5596 - val_loss: 1.1969 - val_sparse_categorical_accuracy: 0.4173\n",
      "Epoch 5/100\n",
      "85176/85176 [==============================] - 41s 486us/sample - loss: 0.6611 - sparse_categorical_accuracy: 0.6005 - val_loss: 1.5067 - val_sparse_categorical_accuracy: 0.2747\n",
      "Epoch 6/100\n",
      "85176/85176 [==============================] - 34s 394us/sample - loss: 0.5816 - sparse_categorical_accuracy: 0.6428 - val_loss: 1.4293 - val_sparse_categorical_accuracy: 0.3483\n",
      "Epoch 7/100\n",
      "85176/85176 [==============================] - 63s 737us/sample - loss: 0.5212 - sparse_categorical_accuracy: 0.6803 - val_loss: 1.3873 - val_sparse_categorical_accuracy: 0.4353\n",
      "Epoch 8/100\n",
      "85176/85176 [==============================] - 40s 465us/sample - loss: 0.4658 - sparse_categorical_accuracy: 0.7192 - val_loss: 1.2081 - val_sparse_categorical_accuracy: 0.5865\n",
      "Epoch 9/100\n",
      "85176/85176 [==============================] - 24s 282us/sample - loss: 0.4290 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.4067 - val_sparse_categorical_accuracy: 0.4716\n",
      "Epoch 10/100\n",
      "85176/85176 [==============================] - 24s 285us/sample - loss: 0.3986 - sparse_categorical_accuracy: 0.7601 - val_loss: 1.2867 - val_sparse_categorical_accuracy: 0.5719\n",
      "Epoch 11/100\n",
      "85176/85176 [==============================] - 26s 304us/sample - loss: 0.3602 - sparse_categorical_accuracy: 0.7883 - val_loss: 1.2360 - val_sparse_categorical_accuracy: 0.5872\n",
      "Epoch 12/100\n",
      "85176/85176 [==============================] - 33s 382us/sample - loss: 0.3350 - sparse_categorical_accuracy: 0.8032 - val_loss: 1.3961 - val_sparse_categorical_accuracy: 0.5828\n",
      "Epoch 13/100\n",
      "85176/85176 [==============================] - 32s 378us/sample - loss: 0.3287 - sparse_categorical_accuracy: 0.8087 - val_loss: 1.4723 - val_sparse_categorical_accuracy: 0.5187\n",
      "Epoch 14/100\n",
      "85176/85176 [==============================] - 42s 490us/sample - loss: 0.2940 - sparse_categorical_accuracy: 0.8309 - val_loss: 1.5043 - val_sparse_categorical_accuracy: 0.5450\n",
      "Epoch 15/100\n",
      "85176/85176 [==============================] - 36s 424us/sample - loss: 0.2787 - sparse_categorical_accuracy: 0.8414 - val_loss: 1.3305 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 16/100\n",
      "85176/85176 [==============================] - 34s 398us/sample - loss: 0.2843 - sparse_categorical_accuracy: 0.8391 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.5663\n",
      "Epoch 17/100\n",
      "85176/85176 [==============================] - 25s 298us/sample - loss: 0.2619 - sparse_categorical_accuracy: 0.8502 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.6266\n",
      "Epoch 18/100\n",
      "85176/85176 [==============================] - 26s 308us/sample - loss: 0.2551 - sparse_categorical_accuracy: 0.8574 - val_loss: 1.6733 - val_sparse_categorical_accuracy: 0.5651\n",
      "Epoch 19/100\n",
      "85176/85176 [==============================] - 50s 586us/sample - loss: 0.2354 - sparse_categorical_accuracy: 0.8677 - val_loss: 1.6762 - val_sparse_categorical_accuracy: 0.5933\n",
      "Epoch 20/100\n",
      "85176/85176 [==============================] - 42s 492us/sample - loss: 0.2229 - sparse_categorical_accuracy: 0.8755 - val_loss: 1.6956 - val_sparse_categorical_accuracy: 0.5992\n",
      "Epoch 21/100\n",
      "85176/85176 [==============================] - 41s 479us/sample - loss: 0.2163 - sparse_categorical_accuracy: 0.8807 - val_loss: 1.5625 - val_sparse_categorical_accuracy: 0.5891\n",
      "Epoch 22/100\n",
      "85176/85176 [==============================] - 23s 272us/sample - loss: 0.2047 - sparse_categorical_accuracy: 0.8892 - val_loss: 1.6256 - val_sparse_categorical_accuracy: 0.5847\n",
      "Epoch 23/100\n",
      "85176/85176 [==============================] - 24s 276us/sample - loss: 0.2101 - sparse_categorical_accuracy: 0.8857 - val_loss: 1.6305 - val_sparse_categorical_accuracy: 0.6422\n",
      "Epoch 24/100\n",
      "85176/85176 [==============================] - 29s 342us/sample - loss: 0.1969 - sparse_categorical_accuracy: 0.8885 - val_loss: 1.9635 - val_sparse_categorical_accuracy: 0.5648\n",
      "Epoch 25/100\n",
      "85176/85176 [==============================] - 35s 412us/sample - loss: 0.1942 - sparse_categorical_accuracy: 0.8935 - val_loss: 1.6352 - val_sparse_categorical_accuracy: 0.6046\n",
      "Epoch 26/100\n",
      "85176/85176 [==============================] - 28s 332us/sample - loss: 0.1844 - sparse_categorical_accuracy: 0.9000 - val_loss: 1.8484 - val_sparse_categorical_accuracy: 0.6224\n",
      "Epoch 27/100\n",
      "85176/85176 [==============================] - 25s 292us/sample - loss: 0.1796 - sparse_categorical_accuracy: 0.9032 - val_loss: 1.6200 - val_sparse_categorical_accuracy: 0.6405\n",
      "Epoch 28/100\n",
      "85176/85176 [==============================] - 30s 353us/sample - loss: 0.1757 - sparse_categorical_accuracy: 0.9052 - val_loss: 1.7332 - val_sparse_categorical_accuracy: 0.6738\n",
      "Epoch 29/100\n",
      "85176/85176 [==============================] - 30s 347us/sample - loss: 0.1712 - sparse_categorical_accuracy: 0.9096 - val_loss: 1.5465 - val_sparse_categorical_accuracy: 0.6427\n",
      "Epoch 30/100\n",
      "85176/85176 [==============================] - 35s 405us/sample - loss: 0.1703 - sparse_categorical_accuracy: 0.9102 - val_loss: 1.5050 - val_sparse_categorical_accuracy: 0.6965\n",
      "Epoch 31/100\n",
      "85176/85176 [==============================] - 28s 325us/sample - loss: 0.1582 - sparse_categorical_accuracy: 0.9156 - val_loss: 1.7743 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 32/100\n",
      "85176/85176 [==============================] - 28s 330us/sample - loss: 0.1595 - sparse_categorical_accuracy: 0.9148 - val_loss: 1.8872 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 33/100\n",
      "85176/85176 [==============================] - 24s 277us/sample - loss: 0.1541 - sparse_categorical_accuracy: 0.9162 - val_loss: 1.6908 - val_sparse_categorical_accuracy: 0.6790\n",
      "Epoch 34/100\n",
      "85176/85176 [==============================] - 25s 291us/sample - loss: 0.1539 - sparse_categorical_accuracy: 0.9204 - val_loss: 1.6870 - val_sparse_categorical_accuracy: 0.6531\n",
      "Epoch 35/100\n",
      "85176/85176 [==============================] - 26s 307us/sample - loss: 0.1491 - sparse_categorical_accuracy: 0.9221 - val_loss: 1.7978 - val_sparse_categorical_accuracy: 0.6346\n",
      "Epoch 36/100\n",
      "85176/85176 [==============================] - 29s 339us/sample - loss: 0.1456 - sparse_categorical_accuracy: 0.9221 - val_loss: 1.7766 - val_sparse_categorical_accuracy: 0.6408\n",
      "Epoch 37/100\n",
      "85176/85176 [==============================] - 27s 319us/sample - loss: 0.1463 - sparse_categorical_accuracy: 0.9222 - val_loss: 1.9102 - val_sparse_categorical_accuracy: 0.6628\n",
      "Epoch 38/100\n",
      "85176/85176 [==============================] - 28s 329us/sample - loss: 0.1377 - sparse_categorical_accuracy: 0.9264 - val_loss: 1.6799 - val_sparse_categorical_accuracy: 0.6684\n",
      "Epoch 39/100\n",
      "85176/85176 [==============================] - 24s 284us/sample - loss: 0.1308 - sparse_categorical_accuracy: 0.9307 - val_loss: 1.5291 - val_sparse_categorical_accuracy: 0.7032\n",
      "Epoch 40/100\n",
      "85176/85176 [==============================] - 32s 381us/sample - loss: 0.1321 - sparse_categorical_accuracy: 0.9318 - val_loss: 1.8905 - val_sparse_categorical_accuracy: 0.6734\n",
      "Epoch 41/100\n",
      "85176/85176 [==============================] - 27s 313us/sample - loss: 0.1359 - sparse_categorical_accuracy: 0.9310 - val_loss: 1.7522 - val_sparse_categorical_accuracy: 0.6923\n",
      "Epoch 42/100\n",
      "85176/85176 [==============================] - 36s 424us/sample - loss: 0.1321 - sparse_categorical_accuracy: 0.9323 - val_loss: 1.6132 - val_sparse_categorical_accuracy: 0.6819\n",
      "Epoch 43/100\n",
      "85176/85176 [==============================] - 49s 576us/sample - loss: 0.1268 - sparse_categorical_accuracy: 0.9343 - val_loss: 1.6199 - val_sparse_categorical_accuracy: 0.7050\n",
      "Epoch 44/100\n",
      "85176/85176 [==============================] - 44s 520us/sample - loss: 0.1310 - sparse_categorical_accuracy: 0.9317 - val_loss: 1.8550 - val_sparse_categorical_accuracy: 0.6426\n",
      "Epoch 45/100\n",
      "85176/85176 [==============================] - 34s 398us/sample - loss: 0.1181 - sparse_categorical_accuracy: 0.9379 - val_loss: 1.7185 - val_sparse_categorical_accuracy: 0.6422\n",
      "Epoch 46/100\n",
      "85176/85176 [==============================] - 30s 346us/sample - loss: 0.1137 - sparse_categorical_accuracy: 0.9396 - val_loss: 1.7763 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 47/100\n",
      "85176/85176 [==============================] - 27s 312us/sample - loss: 0.1160 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.7384 - val_sparse_categorical_accuracy: 0.6510\n",
      "Epoch 48/100\n",
      "85176/85176 [==============================] - 35s 407us/sample - loss: 0.1101 - sparse_categorical_accuracy: 0.9426 - val_loss: 1.7632 - val_sparse_categorical_accuracy: 0.6738\n",
      "Epoch 49/100\n",
      "85176/85176 [==============================] - 50s 584us/sample - loss: 0.1118 - sparse_categorical_accuracy: 0.9423 - val_loss: 1.7500 - val_sparse_categorical_accuracy: 0.6994\n",
      "Epoch 50/100\n",
      "85176/85176 [==============================] - 30s 357us/sample - loss: 0.1062 - sparse_categorical_accuracy: 0.9446 - val_loss: 1.8704 - val_sparse_categorical_accuracy: 0.6322\n",
      "Epoch 51/100\n",
      "85176/85176 [==============================] - 29s 338us/sample - loss: 0.1082 - sparse_categorical_accuracy: 0.9457 - val_loss: 1.7947 - val_sparse_categorical_accuracy: 0.6357\n",
      "Epoch 52/100\n",
      "85176/85176 [==============================] - 33s 385us/sample - loss: 0.1051 - sparse_categorical_accuracy: 0.9447 - val_loss: 1.8888 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 53/100\n",
      "85176/85176 [==============================] - 38s 450us/sample - loss: 0.1095 - sparse_categorical_accuracy: 0.9436 - val_loss: 1.7490 - val_sparse_categorical_accuracy: 0.6652\n",
      "Epoch 54/100\n",
      "85176/85176 [==============================] - 29s 337us/sample - loss: 0.1052 - sparse_categorical_accuracy: 0.9442 - val_loss: 1.7483 - val_sparse_categorical_accuracy: 0.7082\n",
      "Epoch 55/100\n",
      "85176/85176 [==============================] - 25s 294us/sample - loss: 0.0998 - sparse_categorical_accuracy: 0.9476 - val_loss: 1.8841 - val_sparse_categorical_accuracy: 0.7012\n",
      "Epoch 56/100\n",
      "85176/85176 [==============================] - 25s 296us/sample - loss: 0.1046 - sparse_categorical_accuracy: 0.9457 - val_loss: 1.7186 - val_sparse_categorical_accuracy: 0.7112\n",
      "Epoch 57/100\n",
      "85176/85176 [==============================] - 35s 414us/sample - loss: 0.1003 - sparse_categorical_accuracy: 0.9487 - val_loss: 1.6802 - val_sparse_categorical_accuracy: 0.7014\n",
      "Epoch 58/100\n",
      "85176/85176 [==============================] - 28s 331us/sample - loss: 0.0988 - sparse_categorical_accuracy: 0.9502 - val_loss: 1.7505 - val_sparse_categorical_accuracy: 0.6891\n",
      "Epoch 59/100\n",
      "85176/85176 [==============================] - 30s 350us/sample - loss: 0.0973 - sparse_categorical_accuracy: 0.9506 - val_loss: 2.0675 - val_sparse_categorical_accuracy: 0.6610\n",
      "Epoch 60/100\n",
      "85176/85176 [==============================] - 34s 405us/sample - loss: 0.1026 - sparse_categorical_accuracy: 0.9478 - val_loss: 2.2987 - val_sparse_categorical_accuracy: 0.6039\n",
      "Epoch 61/100\n",
      "85176/85176 [==============================] - 32s 375us/sample - loss: 0.0936 - sparse_categorical_accuracy: 0.9519 - val_loss: 1.9205 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 62/100\n",
      "85176/85176 [==============================] - 39s 462us/sample - loss: 0.0964 - sparse_categorical_accuracy: 0.9511 - val_loss: 2.1044 - val_sparse_categorical_accuracy: 0.6124\n",
      "Epoch 63/100\n",
      "85176/85176 [==============================] - 28s 329us/sample - loss: 0.0910 - sparse_categorical_accuracy: 0.9537 - val_loss: 1.8517 - val_sparse_categorical_accuracy: 0.7148\n",
      "Epoch 64/100\n",
      "85176/85176 [==============================] - 35s 410us/sample - loss: 0.0946 - sparse_categorical_accuracy: 0.9523 - val_loss: 1.9108 - val_sparse_categorical_accuracy: 0.6512\n",
      "Epoch 65/100\n",
      "85176/85176 [==============================] - 30s 355us/sample - loss: 0.0969 - sparse_categorical_accuracy: 0.9500 - val_loss: 2.1214 - val_sparse_categorical_accuracy: 0.6102\n",
      "Epoch 66/100\n",
      "85176/85176 [==============================] - 34s 396us/sample - loss: 0.0946 - sparse_categorical_accuracy: 0.9525 - val_loss: 2.0145 - val_sparse_categorical_accuracy: 0.6083\n",
      "Epoch 67/100\n",
      "85176/85176 [==============================] - 35s 412us/sample - loss: 0.0901 - sparse_categorical_accuracy: 0.9557 - val_loss: 1.9616 - val_sparse_categorical_accuracy: 0.6841\n",
      "Epoch 68/100\n",
      "85176/85176 [==============================] - 33s 393us/sample - loss: 0.0875 - sparse_categorical_accuracy: 0.9558 - val_loss: 2.0485 - val_sparse_categorical_accuracy: 0.6318\n",
      "Epoch 69/100\n",
      "85176/85176 [==============================] - 35s 407us/sample - loss: 0.0896 - sparse_categorical_accuracy: 0.9554 - val_loss: 1.8288 - val_sparse_categorical_accuracy: 0.6977\n",
      "Epoch 70/100\n",
      "85176/85176 [==============================] - 34s 399us/sample - loss: 0.0896 - sparse_categorical_accuracy: 0.9558 - val_loss: 1.7762 - val_sparse_categorical_accuracy: 0.7098\n",
      "Epoch 71/100\n",
      "85176/85176 [==============================] - 29s 336us/sample - loss: 0.0878 - sparse_categorical_accuracy: 0.9572 - val_loss: 1.8571 - val_sparse_categorical_accuracy: 0.7157\n",
      "Epoch 72/100\n",
      "85176/85176 [==============================] - 28s 334us/sample - loss: 0.0841 - sparse_categorical_accuracy: 0.9594 - val_loss: 1.7547 - val_sparse_categorical_accuracy: 0.6785\n",
      "Epoch 73/100\n",
      "85176/85176 [==============================] - 27s 314us/sample - loss: 0.0849 - sparse_categorical_accuracy: 0.9566 - val_loss: 1.8503 - val_sparse_categorical_accuracy: 0.7558\n",
      "Epoch 74/100\n",
      "85176/85176 [==============================] - 35s 408us/sample - loss: 0.0790 - sparse_categorical_accuracy: 0.9610 - val_loss: 2.0991 - val_sparse_categorical_accuracy: 0.6674\n",
      "Epoch 75/100\n",
      "85176/85176 [==============================] - 31s 368us/sample - loss: 0.0767 - sparse_categorical_accuracy: 0.9612 - val_loss: 1.9628 - val_sparse_categorical_accuracy: 0.6966\n",
      "Epoch 76/100\n",
      "85176/85176 [==============================] - 28s 333us/sample - loss: 0.0835 - sparse_categorical_accuracy: 0.9582 - val_loss: 1.9050 - val_sparse_categorical_accuracy: 0.6963\n",
      "Epoch 77/100\n",
      "85176/85176 [==============================] - 29s 341us/sample - loss: 0.0827 - sparse_categorical_accuracy: 0.9577 - val_loss: 1.9583 - val_sparse_categorical_accuracy: 0.6932\n",
      "Epoch 78/100\n",
      "85176/85176 [==============================] - 25s 293us/sample - loss: 0.0801 - sparse_categorical_accuracy: 0.9599 - val_loss: 2.0437 - val_sparse_categorical_accuracy: 0.6850\n",
      "Epoch 79/100\n",
      "85176/85176 [==============================] - 31s 362us/sample - loss: 0.0776 - sparse_categorical_accuracy: 0.9612 - val_loss: 2.0954 - val_sparse_categorical_accuracy: 0.6613\n",
      "Epoch 80/100\n",
      "85176/85176 [==============================] - 30s 349us/sample - loss: 0.0792 - sparse_categorical_accuracy: 0.9611 - val_loss: 2.0338 - val_sparse_categorical_accuracy: 0.6569\n",
      "Epoch 81/100\n",
      "85176/85176 [==============================] - 34s 398us/sample - loss: 0.0759 - sparse_categorical_accuracy: 0.9633 - val_loss: 1.8375 - val_sparse_categorical_accuracy: 0.6990\n",
      "Epoch 82/100\n",
      "85176/85176 [==============================] - 28s 332us/sample - loss: 0.0746 - sparse_categorical_accuracy: 0.9642 - val_loss: 2.0086 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 83/100\n",
      "85176/85176 [==============================] - 24s 282us/sample - loss: 0.0787 - sparse_categorical_accuracy: 0.9614 - val_loss: 2.3341 - val_sparse_categorical_accuracy: 0.6191\n",
      "Epoch 84/100\n",
      "85176/85176 [==============================] - 27s 317us/sample - loss: 0.0797 - sparse_categorical_accuracy: 0.9602 - val_loss: 1.9389 - val_sparse_categorical_accuracy: 0.7207\n",
      "Epoch 85/100\n",
      "85176/85176 [==============================] - 27s 322us/sample - loss: 0.0791 - sparse_categorical_accuracy: 0.9617 - val_loss: 2.0303 - val_sparse_categorical_accuracy: 0.6632\n",
      "Epoch 86/100\n",
      "85176/85176 [==============================] - 23s 264us/sample - loss: 0.0751 - sparse_categorical_accuracy: 0.9624 - val_loss: 1.9516 - val_sparse_categorical_accuracy: 0.6565\n",
      "Epoch 87/100\n",
      "85176/85176 [==============================] - 24s 287us/sample - loss: 0.0728 - sparse_categorical_accuracy: 0.9619 - val_loss: 2.0817 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 88/100\n",
      "85176/85176 [==============================] - 24s 282us/sample - loss: 0.0695 - sparse_categorical_accuracy: 0.9653 - val_loss: 1.8897 - val_sparse_categorical_accuracy: 0.7446\n",
      "Epoch 89/100\n",
      "85176/85176 [==============================] - 25s 290us/sample - loss: 0.0679 - sparse_categorical_accuracy: 0.9666 - val_loss: 2.0701 - val_sparse_categorical_accuracy: 0.7038\n",
      "Epoch 90/100\n",
      "85176/85176 [==============================] - 22s 264us/sample - loss: 0.0741 - sparse_categorical_accuracy: 0.9630 - val_loss: 2.0621 - val_sparse_categorical_accuracy: 0.6718\n",
      "Epoch 91/100\n",
      "85176/85176 [==============================] - 22s 263us/sample - loss: 0.0755 - sparse_categorical_accuracy: 0.9624 - val_loss: 1.9007 - val_sparse_categorical_accuracy: 0.7481\n",
      "Epoch 92/100\n",
      "85176/85176 [==============================] - 23s 270us/sample - loss: 0.0708 - sparse_categorical_accuracy: 0.9667 - val_loss: 2.6609 - val_sparse_categorical_accuracy: 0.5549\n",
      "Epoch 93/100\n",
      "85176/85176 [==============================] - 20s 238us/sample - loss: 0.0726 - sparse_categorical_accuracy: 0.9654 - val_loss: 2.1797 - val_sparse_categorical_accuracy: 0.6248\n",
      "Epoch 94/100\n",
      "85176/85176 [==============================] - 25s 289us/sample - loss: 0.0710 - sparse_categorical_accuracy: 0.9651 - val_loss: 2.2702 - val_sparse_categorical_accuracy: 0.6412\n",
      "Epoch 95/100\n",
      "85176/85176 [==============================] - 22s 263us/sample - loss: 0.0688 - sparse_categorical_accuracy: 0.9654 - val_loss: 1.8650 - val_sparse_categorical_accuracy: 0.7156\n",
      "Epoch 96/100\n",
      "85176/85176 [==============================] - 21s 245us/sample - loss: 0.0727 - sparse_categorical_accuracy: 0.9650 - val_loss: 2.0213 - val_sparse_categorical_accuracy: 0.7109\n",
      "Epoch 97/100\n",
      "85176/85176 [==============================] - 30s 347us/sample - loss: 0.0700 - sparse_categorical_accuracy: 0.9663 - val_loss: 1.9709 - val_sparse_categorical_accuracy: 0.7149\n",
      "Epoch 98/100\n",
      "85176/85176 [==============================] - 24s 278us/sample - loss: 0.0664 - sparse_categorical_accuracy: 0.9674 - val_loss: 1.9244 - val_sparse_categorical_accuracy: 0.7517\n",
      "Epoch 99/100\n",
      "85176/85176 [==============================] - 24s 278us/sample - loss: 0.0756 - sparse_categorical_accuracy: 0.9659 - val_loss: 2.0469 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 100/100\n",
      "85176/85176 [==============================] - 22s 261us/sample - loss: 0.0662 - sparse_categorical_accuracy: 0.9687 - val_loss: 1.9565 - val_sparse_categorical_accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"###\n",
    "### TRAIN      \\t total: {len(train_x)} \\t holds: {train_y.count(1)} \\t buys: {train_y.count(2)} \\t sells: {train_y.count(0)}\n",
    "### VALIDATION \\t total: {len(validation_x)} \\t holds: {validation_y.count(1)} \\t buys: {validation_y.count(2)} \\t sells: {validation_y.count(0)}\n",
    "###\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_x.shape[1:])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(train_x.shape[1:])))\n",
    "\n",
    "n_cells = 256 # 128\n",
    "do_layer  = 0.2\n",
    "\n",
    "model.add(Dense(n_cells, activation='relu'))\n",
    "model.add(Dropout(do_layer))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(n_cells, activation='relu'))\n",
    "model.add(Dropout(do_layer))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(n_cells, activation='relu'))\n",
    "model.add(Dropout(do_layer))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "# unique file name that will include the epoch and the validation acc for that epoch\n",
    "filepath = NNNAME + \"-{epoch:02d}-{val_sparse_categorical_accuracy:.3f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_sparse_categorical_accuracy',\n",
    "                                                   verbose=1, save_best_only=True, mode='max'))  # saves only the best ones\n",
    "train_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_y),\n",
    "                                                 train_y)\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    "    class_weight=dict(enumerate(train_weights)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MODEL: \t DENSE-60-SEQ-12-PRED-1586392233\n",
      "### Test loss: \t 5.726777190600121\n",
      "### Test accuracy: \t 0.7059211\n"
     ]
    }
   ],
   "source": [
    "val_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(validation_y),\n",
    "                                                 validation_y)\n",
    "\n",
    "val_sample_weights = training_utils.standardize_weights(np.array(validation_y), class_weight=dict(enumerate(val_weights)))\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0, sample_weight=val_sample_weights)\n",
    "# Save model\n",
    "if SAVE:\n",
    "    model.save(\"models/{}\".format(NAME))\n",
    "    print(f'### MODEL: \\t {NAME}')\n",
    "else:\n",
    "    print('[model not saved]')\n",
    "print('### Test loss: \\t', score[0])\n",
    "print('### Test accuracy: \\t', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF:  [[140, 1345, 239], [1384, 14615, 1749], [149, 1382, 243]]\n",
      "WACC:   0.605  FRCS:  0.081 0.823 0.137\n"
     ]
    }
   ],
   "source": [
    "pyv = model.predict(validation_x)\n",
    "py = list(np.argmax(pyv, axis=1).flatten())\n",
    "confs = list(np.max(pyv, axis=1).flatten())\n",
    "\n",
    "val_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(validation_y),\n",
    "                                                 validation_y)\n",
    "\n",
    "table = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "for i, y in enumerate(py):\n",
    "    table[int(validation_y[i])][int(y)] +=1\n",
    "\n",
    "acc = np.sum(table) / (np.sum(table) + val_weights[0]*(table[0][1] + table[0][2] )+ val_weights[1]*(table[1][0] + table[1][2]) + val_weights[2]*(table[2][0] + table[2][1]))\n",
    "\n",
    "# print(py)\n",
    "print(\"CONF: \", table)\n",
    "print(\"WACC:  \", round(acc, 3), \" FRCS: \", round(table[0][0] / np.sum(table[0]), 3),\n",
    "round(table[1][1] / np.sum(table[1]), 3),\n",
    "round(table[2][2] / np.sum(table[2]), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python36964bitlearnenvconda73a6b7ead5a84093afcb9dca25787081"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
